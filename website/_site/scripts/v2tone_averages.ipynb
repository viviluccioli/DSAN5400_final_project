{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369bc026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "fox2018 = pd.read_csv(\"../../data/fox/fox2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74070b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing source: fox\n",
      "  Processing fox2016.csv (Year: 2016)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing fox2017.csv (Year: 2017)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing fox2015.csv (Year: 2015)\n",
      "    Processed 11000 articles, found 11 months with data\n",
      "  Processing fox2023.csv (Year: 2023)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing fox2022.csv (Year: 2022)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing fox2020.csv (Year: 2020)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing fox2021.csv (Year: 2021)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing fox2025.csv (Year: 2025)\n",
      "    Processed 3079 articles, found 4 months with data\n",
      "  Processing fox2019.csv (Year: 2019)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing fox2018.csv (Year: 2018)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing fox2024.csv (Year: 2024)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "Processing source: abc\n",
      "  Processing abc2020.csv (Year: 2020)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing abc2021.csv (Year: 2021)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing abc2023.csv (Year: 2023)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing abc2022.csv (Year: 2022)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing abc2025.csv (Year: 2025)\n",
      "    Processed 3064 articles, found 4 months with data\n",
      "  Processing abc2019.csv (Year: 2019)\n",
      "    Processed 11909 articles, found 12 months with data\n",
      "  Processing abc2018.csv (Year: 2018)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing abc2024.csv (Year: 2024)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing abc2015.csv (Year: 2015)\n",
      "    Processed 11000 articles, found 11 months with data\n",
      "  Processing abc2016.csv (Year: 2016)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing abc2017.csv (Year: 2017)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "Processing source: msnbc\n",
      "  Processing msnbc2024.csv (Year: 2024)\n",
      "    Processed 9185 articles, found 12 months with data\n",
      "  Processing msnbc2018.csv (Year: 2018)\n",
      "    Processed 8784 articles, found 12 months with data\n",
      "  Processing msnbc2019.csv (Year: 2019)\n",
      "    Processed 12000 articles, found 12 months with data\n",
      "  Processing msnbc2025.csv (Year: 2025)\n",
      "    Processed 2285 articles, found 4 months with data\n",
      "  Processing msnbc2021.csv (Year: 2021)\n",
      "    Processed 10467 articles, found 12 months with data\n",
      "  Processing msnbc2020.csv (Year: 2020)\n",
      "    Processed 10970 articles, found 12 months with data\n",
      "  Processing msnbc2022.csv (Year: 2022)\n",
      "    Processed 8684 articles, found 12 months with data\n",
      "  Processing msnbc2023.csv (Year: 2023)\n",
      "    Processed 8932 articles, found 12 months with data\n",
      "  Processing msnbc2015.csv (Year: 2015)\n",
      "    Processed 7372 articles, found 11 months with data\n",
      "  Processing msnbc2017.csv (Year: 2017)\n",
      "    Processed 2799 articles, found 12 months with data\n",
      "  Processing msnbc2016.csv (Year: 2016)\n",
      "    Processed 5339 articles, found 12 months with data\n",
      "\n",
      "Analysis complete. Results saved to ../data/gdelt_monthly_tone_averages.csv\n",
      "Total records: 369\n",
      "\n",
      "Sample of results:\n",
      "    source  year  month  average_tone\n",
      "211    abc  2015      2     -2.885305\n",
      "212    abc  2015      3     -2.876779\n",
      "213    abc  2015      4     -2.966378\n",
      "214    abc  2015      5     -3.123535\n",
      "215    abc  2015      6     -2.872657\n",
      "216    abc  2015      7     -2.900161\n",
      "217    abc  2015      8     -3.342951\n",
      "218    abc  2015      9     -2.907180\n",
      "219    abc  2015     10     -3.110520\n",
      "220    abc  2015     11     -3.221210\n",
      "\n",
      "Overall average tone by source:\n",
      "  source  average_tone\n",
      "0    abc     -3.089427\n",
      "1    fox     -2.683923\n",
      "2  msnbc     -2.625040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the base directory where your data is stored\n",
    "data_dir = \"../../data\"\n",
    "\n",
    "# Define the sources and their respective directories\n",
    "sources = {\n",
    "    \"fox\": os.path.join(data_dir, \"fox\"),\n",
    "    \"abc\": os.path.join(data_dir, \"abc\"),\n",
    "    \"msnbc\": os.path.join(data_dir, \"msnbc\")\n",
    "}\n",
    "\n",
    "# Function to extract the first value from V2Tone string\n",
    "def extract_tone_score(tone_str):\n",
    "    if pd.isna(tone_str):\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        # Split by comma and take the first value\n",
    "        return float(str(tone_str).split(',')[0])\n",
    "    except (ValueError, IndexError):\n",
    "        return np.nan\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Process each source\n",
    "for source_name, source_dir in sources.items():\n",
    "    print(f\"Processing source: {source_name}\")\n",
    "    \n",
    "    # Get all CSV files in the source directory\n",
    "    csv_files = [f for f in os.listdir(source_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        # Extract year from filename\n",
    "        year = int(csv_file.replace(f\"{source_name}\", \"\").replace(\".csv\", \"\"))\n",
    "        file_path = os.path.join(source_dir, csv_file)\n",
    "        \n",
    "        print(f\"  Processing {csv_file} (Year: {year})\")\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Check if required columns exist\n",
    "            if 'parsed_date' not in df.columns or 'V2Tone' not in df.columns:\n",
    "                print(f\"    Error: Missing required columns in {csv_file}\")\n",
    "                continue\n",
    "                \n",
    "            # Convert parsed_date to datetime and extract month\n",
    "            df['datetime'] = pd.to_datetime(df['parsed_date'])\n",
    "            df['month'] = df['datetime'].dt.month\n",
    "            \n",
    "            # Extract the first tone score from V2Tone\n",
    "            df['tone_score'] = df['V2Tone'].apply(extract_tone_score)\n",
    "            \n",
    "            # Calculate monthly averages\n",
    "            monthly_avg = df.groupby('month')['tone_score'].mean().reset_index()\n",
    "            \n",
    "            # Add source and year columns\n",
    "            monthly_avg['source'] = source_name\n",
    "            monthly_avg['year'] = year\n",
    "            \n",
    "            # Append to results\n",
    "            results.append(monthly_avg)\n",
    "            \n",
    "            print(f\"    Processed {len(df)} articles, found {monthly_avg.shape[0]} months with data\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing {csv_file}: {str(e)}\")\n",
    "    \n",
    "# Combine all results\n",
    "if results:\n",
    "    all_results = pd.concat(results, ignore_index=True)\n",
    "    \n",
    "    # Rename columns to match requested output\n",
    "    all_results = all_results.rename(columns={'tone_score': 'average_tone'})\n",
    "    \n",
    "    # Reorder columns\n",
    "    all_results = all_results[['source', 'year', 'month', 'average_tone']]\n",
    "    \n",
    "    # Sort by source, year, and month\n",
    "    all_results = all_results.sort_values(['source', 'year', 'month'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = \"../data/gdelt_monthly_tone_averages.csv\"\n",
    "    all_results.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nAnalysis complete. Results saved to {output_file}\")\n",
    "    print(f\"Total records: {len(all_results)}\")\n",
    "    \n",
    "    # Display sample of results\n",
    "    print(\"\\nSample of results:\")\n",
    "    print(all_results.head(10))\n",
    "    \n",
    "    # Calculate overall source averages for comparison\n",
    "    source_avg = all_results.groupby('source')['average_tone'].mean().reset_index()\n",
    "    print(\"\\nOverall average tone by source:\")\n",
    "    print(source_avg)\n",
    "else:\n",
    "    print(\"No results generated. Please check the data files and paths.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
